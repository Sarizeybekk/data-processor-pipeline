import streamlit as st

st.set_page_config(
    page_title="LLM Veri Temizleme ve Ã–n-Ä°ÅŸleme AracÄ±",
    page_icon="ğŸ§¹",
    layout="wide",
)

import pandas as pd
import os
import sys
from pathlib import Path

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

import_errors = []

try:
    from modules.language_detector import detect_languages, separate_by_language
except ImportError as e:
    import_errors.append(f"language_detector modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")

try:
    import modules.duplicate_detector as duplicate_detector
except ImportError as e:
    import_errors.append(f"duplicate_detector modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")

try:
    from modules.spam_detector import detect_spam
except ImportError as e:
    import_errors.append(f"spam_detector modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")

try:
    from modules.text_cleaner import clean_text
except ImportError as e:
    import_errors.append(f"text_cleaner modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")

try:
    from modules.prompt_converter import convert_to_prompt_completion
except ImportError as e:
    import_errors.append(f"prompt_converter modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")

try:
    from utils.file_handler import save_processed_data, load_file
except ImportError as e:
    import_errors.append(f"file_handler modÃ¼lÃ¼ yÃ¼klenemedi: {str(e)}")


if import_errors:
    st.error("BazÄ± modÃ¼ller yÃ¼klenemedi. LÃ¼tfen proje yapÄ±sÄ±nÄ± kontrol edin:")
    for error in import_errors:
        st.warning(error)

st.sidebar.header("Ä°ÅŸlem AyarlarÄ±")


uploaded_file = st.sidebar.file_uploader("Veri dosyasÄ± yÃ¼kle", type=["csv", "txt", "json"])

st.sidebar.subheader("Ä°ÅŸlem SeÃ§enekleri")
detect_lang = st.sidebar.checkbox("Dil TanÄ±ma & AyÄ±rma", value=True, disabled='language_detector' in [
    e.split(':')[0].strip().replace(' modÃ¼lÃ¼ yÃ¼klenemedi', '') for e in import_errors])
detect_dups = st.sidebar.checkbox("Duplicate Tespiti", value=True, disabled='duplicate_detector' in [
    e.split(':')[0].strip().replace(' modÃ¼lÃ¼ yÃ¼klenemedi', '') for e in import_errors])
detect_spam_option = st.sidebar.checkbox("Spam & Reklam Tespiti", value=True, disabled='spam_detector' in [
    e.split(':')[0].strip().replace(' modÃ¼lÃ¼ yÃ¼klenemedi', '') for e in import_errors])
clean_text_option = st.sidebar.checkbox("Metin DÃ¼zeltme", value=True, disabled='text_cleaner' in [
    e.split(':')[0].strip().replace(' modÃ¼lÃ¼ yÃ¼klenemedi', '') for e in import_errors])
convert_prompt = st.sidebar.checkbox("Prompt-Completion DÃ¶nÃ¼ÅŸtÃ¼rme", value=True, disabled='prompt_converter' in [
    e.split(':')[0].strip().replace(' modÃ¼lÃ¼ yÃ¼klenemedi', '') for e in import_errors])

with st.sidebar.expander("Ä°leri DÃ¼zey Ayarlar"):

    target_languages = st.multiselect(
        "Hedef Diller",
        ["TÃ¼rkÃ§e", "Ä°ngilizce", "Almanca", "FransÄ±zca", "Ä°spanyolca", "DiÄŸer"],
        default=["TÃ¼rkÃ§e", "Ä°ngilizce"]
    )

    similarity_threshold = st.slider(
        "Benzerlik EÅŸiÄŸi",
        min_value=0.5,
        max_value=1.0,
        value=0.85,
        step=0.01
    )

    spam_threshold = st.slider(
        "Spam EÅŸiÄŸi",
        min_value=0.1,
        max_value=1.0,
        value=0.7,
        step=0.01
    )

    normalize_case = st.checkbox("BÃ¼yÃ¼k/KÃ¼Ã§Ã¼k Harf Normalizasyonu", value=True)
    remove_extra_spaces = st.checkbox("Fazla BoÅŸluklarÄ± KaldÄ±r", value=True)
    fix_punctuation = st.checkbox("Noktalama Ä°ÅŸaretlerini DÃ¼zelt", value=True)

    prompt_format = st.selectbox(
        "Prompt FormatÄ±",
        ["Soru-Cevap", "Talimat-YanÄ±t", "Diyalog", "Ã–zel"]
    )

process_button = st.sidebar.button("Ä°ÅŸlemi BaÅŸlat")


if uploaded_file is not None:

    file_details = {"Dosya AdÄ±": uploaded_file.name, "Dosya Tipi": uploaded_file.type,
                    "Dosya Boyutu": f"{uploaded_file.size / 1024:.2f} KB"}
    st.write("### YÃ¼klenen Dosya Bilgileri")
    st.json(file_details)

    df = load_file(uploaded_file)

    if df is not None:
        st.write("### Veri Ã–n Ä°zleme (Ä°lk 5 SatÄ±r)")
        st.dataframe(df.head())

        if process_button:
            progress_bar = st.progress(0)
            status_text = st.empty()

            results_container = st.container()

            with results_container:
                st.write("## Ä°ÅŸlem SonuÃ§larÄ±")

                processed_df = df.copy()
                steps_completed = 0
                total_steps = sum([detect_lang, detect_dups, detect_spam_option, clean_text_option, convert_prompt])

                if detect_lang:
                    status_text.text("Dil tanÄ±ma ve ayÄ±rma iÅŸlemi yapÄ±lÄ±yor...")

                    if "text" in processed_df.columns:
                        processed_df["detected_language"] = processed_df["text"].apply(detect_languages)

                        language_map = {
                            "TÃ¼rkÃ§e": "tr",
                            "Ä°ngilizce": "en",
                            "Almanca": "de",
                            "FransÄ±zca": "fr",
                            "Ä°spanyolca": "es"
                        }
                        target_lang_codes = [language_map.get(lang, lang) for lang in target_languages]

                        processed_df = processed_df[processed_df["detected_language"].isin(target_lang_codes)]

                        lang_stats = processed_df["detected_language"].value_counts()
                        st.write("### Dil DaÄŸÄ±lÄ±mÄ±")
                        st.bar_chart(lang_stats)

                    steps_completed += 1
                    progress_bar.progress(steps_completed / total_steps)


                if detect_dups:
                    status_text.text("Duplicate tespiti yapÄ±lÄ±yor...")

                    if "text" in processed_df.columns:

                        processed_df["is_duplicate"] = duplicate_detector.detect_duplicates(processed_df["text"],
                                                                                            similarity_threshold)

                        unique_count_before = len(processed_df)
                        processed_df = processed_df[~processed_df["is_duplicate"]]
                        unique_count_after = len(processed_df)

                        st.write(f"### Duplicate Tespiti SonuÃ§larÄ±")
                        st.write(f"KaldÄ±rÄ±lan duplicate sayÄ±sÄ±: {unique_count_before - unique_count_after}")

                    steps_completed += 1
                    progress_bar.progress(steps_completed / total_steps)

                if detect_spam_option:
                    status_text.text("Spam ve reklam iÃ§eriÄŸi tespiti yapÄ±lÄ±yor...")

                    if "text" in processed_df.columns:
                        processed_df["spam_score"] = processed_df["text"].apply(lambda x: detect_spam(x))

                        non_spam_count_before = len(processed_df)
                        processed_df = processed_df[processed_df["spam_score"] < spam_threshold]
                        non_spam_count_after = len(processed_df)

                        st.write(f"### Spam Tespiti SonuÃ§larÄ±")
                        st.write(
                            f"Filtrelenen spam/reklam iÃ§eriÄŸi sayÄ±sÄ±: {non_spam_count_before - non_spam_count_after}")

                    steps_completed += 1
                    progress_bar.progress(steps_completed / total_steps)

                if clean_text_option:
                    status_text.text("Metin temizleme ve dÃ¼zeltme iÅŸlemi yapÄ±lÄ±yor...")

                    if "text" in processed_df.columns:

                        clean_params = {
                            "normalize_case": normalize_case,
                            "remove_extra_spaces": remove_extra_spaces,
                            "fix_punctuation": fix_punctuation
                        }

                        processed_df["cleaned_text"] = processed_df["text"].apply(
                            lambda x: clean_text(x, **clean_params)
                        )


                        st.write("### Metin Temizleme Ã–rnekleri")
                        sample_df = processed_df[["text", "cleaned_text"]].head(3)
                        st.dataframe(sample_df)

                    steps_completed += 1
                    progress_bar.progress(steps_completed / total_steps)

                if convert_prompt:
                    status_text.text("Prompt-completion dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi yapÄ±lÄ±yor...")

                    text_column = "cleaned_text" if "cleaned_text" in processed_df.columns else "text"

                    if text_column in processed_df.columns:
                        prompt_completion_df = convert_to_prompt_completion(
                            processed_df,
                            text_column=text_column,
                            format_type=prompt_format
                        )

                        st.write("### Prompt-Completion DÃ¶nÃ¼ÅŸÃ¼m Ã–rnekleri")
                        if not prompt_completion_df.empty:
                            st.dataframe(prompt_completion_df[["prompt", "completion"]].head(3))

                            processed_df = prompt_completion_df
                        else:
                            st.warning("Prompt-completion dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in uygun veri bulunamadÄ±.")

                    steps_completed += 1
                    progress_bar.progress(steps_completed / total_steps)

                status_text.text("Ä°ÅŸlem tamamlandÄ±!")


                if not processed_df.empty:

                    output_filename = f"processed_{uploaded_file.name.split('.')[0]}.csv"
                    csv = processed_df.to_csv(index=False)

                    st.write("### Ä°ÅŸlenmiÅŸ Veri")
                    st.dataframe(processed_df.head(10))


                    st.write("### Ä°ÅŸlem Ä°statistikleri")
                    st.write(f"BaÅŸlangÄ±Ã§ satÄ±r sayÄ±sÄ±: {len(df)}")
                    st.write(f"Ä°ÅŸlem sonrasÄ± satÄ±r sayÄ±sÄ±: {len(processed_df)}")
                    st.write(f"Temizlenen veri oranÄ±: {(1 - len(processed_df) / len(df)) * 100:.2f}%")


                    st.download_button(
                        label="Ä°ÅŸlenmiÅŸ Veriyi Ä°ndir",
                        data=csv,
                        file_name=output_filename,
                        mime="text/csv"
                    )
                else:
                    st.error("Ä°ÅŸlem sonrasÄ± veri boÅŸ. Filtreleme parametrelerini kontrol ediniz.")
    else:
        st.error("Dosya okunamadÄ±. LÃ¼tfen dosya formatÄ±nÄ± kontrol ediniz.")
else:
    st.info(" BaÅŸlamak iÃ§in sol menÃ¼den bir dosya yÃ¼kleyin ve iÅŸlem seÃ§eneklerini ayarlayÄ±n.")


    st.write("##  Ä°ÅŸ AkÄ±ÅŸÄ±")
    st.write("""
    1. **Dil TanÄ±ma & AyÄ±rma**: Verilerin dilini otomatik olarak tespit eder ve istediÄŸiniz dilleri filtrelemenize olanak tanÄ±r.
    2. **Duplicate Tespiti**: AynÄ± veya Ã§ok benzer iÃ§erikleri tespit ederek veri setinden Ã§Ä±karÄ±r.
    3. **Spam & Reklam Tespiti**: Spam veya reklam iÃ§eriÄŸi olabilecek metinleri tespit eder.
    4. **Metin DÃ¼zeltme**: Metinlerdeki biÃ§imsel sorunlarÄ± giderir, fazla boÅŸluklarÄ± kaldÄ±rÄ±r, noktalama iÅŸaretlerini dÃ¼zeltir.
    5. **Prompt-Completion DÃ¶nÃ¼ÅŸtÃ¼rme**: Metinleri, LLM eÄŸitimi iÃ§in prompt-completion Ã§iftlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """)

    st.write("##  Desteklenen Veri FormatlarÄ±")
    st.code("""
    # CSV Ã–rneÄŸi:
    id,text,metadata
    1,"Bu bir Ã¶rnek metindir.","{'source': 'web'}"
    2,"This is a sample text.","{'source': 'book'}"

    # JSON Ã–rneÄŸi:
    [
        {"id": 1, "text": "Bu bir Ã¶rnek metindir.", "metadata": {"source": "web"}},
        {"id": 2, "text": "This is a sample text.", "metadata": {"source": "book"}}
    ]
    """)

st.markdown("---")
st.markdown(" LLM Veri Temizleme ve Ã–n-Ä°ÅŸleme AracÄ± ")